{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import os\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skmultilearn.adapt import mlknn\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['Title', 'Body', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tag_count\"] = df[\"Tags\"].apply(lambda row : len(str(row).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tag_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer= lambda text : text.split(\" \"))\n",
    "tag_dtm = vectorizer.fit_transform(df[\"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = vectorizer.get_feature_names()\n",
    "tags[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = tag_dtm.sum(axis=0).A1\n",
    "result = dict(zip(tags,freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.DataFrame(result.items(), columns=[\"Tags\", \"Counts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df_sorted = tag_df.sort_values(['Counts'], ascending=False)\n",
    "tag_counts = tag_df_sorted[\"Counts\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tag_counts[:100])\n",
    "plt.scatter(x= list(range(0,100,5)), y = tag_counts[0:100:5], c= 'orange',label = \"Quantiles with 5 % intervals\")\n",
    "plt.scatter(x= list(range(0,100,25)), y = tag_counts[0:100:25], c = \"red\", label = \"Quantiles with 25th % intervals\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Tag Number\")\n",
    "plt.ylabel(\"Number of times the tag Appear\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color='black',\n",
    "         width = 1600,\n",
    "         height = 800).generate_from_frequencies(result)\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.arange(30)\n",
    "tag_df_sorted.head(30).plot(kind='bar')\n",
    "plt.xticks(i, tag_df_sorted['Tags'][:30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def striphtml(data):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr,' ',str(data))\n",
    "    return cleantext\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "preprocessed_data_list=[]\n",
    "questions_with_code=0\n",
    "len_pre=0\n",
    "len_post=0\n",
    "questions_proccesed = 0\n",
    "prepared_df = pd.DataFrame(columns=['question','code','tags','words_pre','words_post','is_code'])\n",
    "for row in random_df.iterrows():\n",
    "\n",
    "    is_code = 0\n",
    "\n",
    "    #As title seems very important feature Hence increasing title weight by adding it 3 times\n",
    "    title, question, tags = 3*(' ' +row[1][1]), row[1][2], row[1][3]\n",
    "\n",
    "    if '<code>' in question:\n",
    "        questions_with_code+=1\n",
    "        is_code = 1\n",
    "    x = len(question)+len(title)\n",
    "    len_pre+=x\n",
    "\n",
    "    code = str(re.findall(r'<code>(.*?)</code>', question, flags=re.DOTALL))\n",
    "\n",
    "    question=re.sub('<code>(.*?)</code>', '', question, flags=re.MULTILINE|re.DOTALL)\n",
    "    question=striphtml(question.encode('utf-8'))\n",
    "\n",
    "    title=title.encode('utf-8')\n",
    "\n",
    "    question=str(title)+\" \"+str(question)\n",
    "    question=re.sub(r'[^A-Za-z]+',' ',question)\n",
    "    words=word_tokenize(str(question.lower()))\n",
    "\n",
    "    #Removing all single letter and and stopwords from question exceptt for the letter 'c'\n",
    "    question=' '.join(str(stemmer.stem(j)) for j in words if j not in stop_words and (len(j)!=1 or j=='c'))\n",
    "\n",
    "    len_post+=len(question)\n",
    "    processed_di = {\n",
    "        \"question\": question,\n",
    "        \"code\": code,\n",
    "        \"tags\": tags,\n",
    "        \"words_pre\": x,\n",
    "        \"words_post\": len(question),\n",
    "        \"is_code\" : is_code\n",
    "    }\n",
    "    \n",
    "    prepared_df.loc[len(prepared_df.index)] = [question,code,tags,x,len(question),is_code]\n",
    "    questions_proccesed += 1\n",
    "    if (questions_proccesed%100000==0):\n",
    "        print(\"number of questions completed=\",questions_proccesed)\n",
    "\n",
    "no_dup_avg_len_pre=(len_pre*1.0)/questions_proccesed\n",
    "no_dup_avg_len_post=(len_post*1.0)/questions_proccesed\n",
    "\n",
    "print( \"Avg. length of questions(Title+Body) before processing: %d\"%no_dup_avg_len_pre)\n",
    "print( \"Avg. length of questions(Title+Body) after processing: %d\"%no_dup_avg_len_post)\n",
    "print (\"Percent of questions containing code: %d\"%((questions_with_code*100.0)/questions_proccesed))\n",
    "\n",
    "print(\"Time taken to run this cell :\", datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = prepared_df[[\"question\",\"tags\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer= lambda text : text.split(), binary=True)\n",
    "multilabel_y = vectorizer.fit_transform(preprocessed_data[\"tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_y.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tags_to_choose(n):\n",
    "    t = multilabel_y.sum(axis=0).tolist()[0]\n",
    "    sorted_tags_i = sorted(range(len(t)), key=lambda i: t[i], reverse=True)\n",
    "    multilabel_yn=multilabel_y[:,sorted_tags_i[:n]]\n",
    "    return multilabel_yn\n",
    "\n",
    "def questions_explained_fn(n):\n",
    "    multilabel_yn = tags_to_choose(n)\n",
    "    x= multilabel_yn.sum(axis=1)\n",
    "    return (np.count_nonzero(x==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_explained = []\n",
    "total_tags = multilabel_y.shape[1]\n",
    "total_qs = preprocessed_data.shape[0]\n",
    "\n",
    "for i in range(500, total_tags, 100):\n",
    "    question_explained.append(np.round(((total_qs-questions_explained_fn(i))/total_qs)*100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(question_explained)\n",
    "xlabel = list(500+np.array(range(-50,450,50))*50)\n",
    "ax.set_xticklabels(xlabel)\n",
    "plt.xlabel(\"Number of tags\")\n",
    "plt.ylabel(\"Number Questions coverd partially\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# you can choose any number of tags based on your computing power, minimun is 50(it covers 90% of the tags)\n",
    "print(\"with \",5500,\"tags we are covering \",question_explained[50],\"% of questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_yx = tags_to_choose(5500)\n",
    "print(\"number of questions that are not covered :\", questions_explained_fn(5500),\"out of \", total_qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_yx.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of tags in sample :\", multilabel_y.shape[1])\n",
    "print(\"number of tags taken :\", multilabel_yx.shape[1],\"(\",(multilabel_yx.shape[1]/multilabel_y.shape[1])*100,\"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size=preprocessed_data.shape[0]\n",
    "train_size=int(0.80*total_size)\n",
    "\n",
    "x_train=preprocessed_data.head(train_size)\n",
    "x_test=preprocessed_data.tail(total_size - train_size)\n",
    "\n",
    "y_train = multilabel_yx[0:train_size,:]\n",
    "y_test = multilabel_yx[train_size:total_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of data points in train data :\", y_train.shape)\n",
    "print(\"Number of data points in test data :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(min_df=0.00009,max_features=200000,smooth_idf=True,norm='l2',\\\n",
    "               tokenizer=lambda x : x.split(),sublinear_tf=False, ngram_range=(1,3) )\n",
    "x_train_vectors = tfidf_vect.fit_transform(x_train['question'])\n",
    "x_test_vectors = tfidf_vect.transform(x_test['question'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions of train data X:\",x_train_vectors.shape, \"Y :\",y_train.shape)\n",
    "print(\"Dimensions of test data X:\",x_test_vectors.shape,\"Y:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = OneVsRestClassifier(SGDClassifier(loss='log', alpha=0.00001, penalty='l1'), n_jobs=-1)\n",
    "classifier.fit(x_train_vectors,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(x_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy \", metrics.accuracy_score(y_test,predictions))\n",
    "print(\"macro f1 score \",metrics.f1_score(y_test,predictions, average='macro'))\n",
    "print(\"micro f1 score \", metrics.f1_score(y_test, predictions, average='micro'))\n",
    "print(\"hamming loss \", metrics.hamming_loss(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
